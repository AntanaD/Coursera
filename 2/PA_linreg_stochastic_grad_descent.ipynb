{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('C:\\Users\\gost_\\Downloads\\dvertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = adver_data.values[:, 0:3]\n",
    "y = adver_data.values[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means, stds = X.mean(axis=0), X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = (X-means)/stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.hstack((np.reshape(np.ones(len(X)),(len(X[:,0]),1)),X))\n",
    "X[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return np.mean((y - y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    }
   ],
   "source": [
    "answer1 = mserror(y, (np.median(y)*np.ones((len(y), 1))))\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.dot(np.linalg.pinv(X),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.0225       3.91925365   2.79206274  -0.02253861]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.dot([1,0,0,0], norm_eq_weights)\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y, linear_prediction(X, norm_eq_weights))\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    grad0 = (np.sum(w*X[train_ind, :])-y[train_ind])/len(y)\n",
    "    grad1 = X[train_ind, 1]*(np.sum(w*X[train_ind, :])-y[train_ind])/len(y)\n",
    "    grad2 = X[train_ind, 2]*(np.sum(w*X[train_ind, :])-y[train_ind])/len(y)\n",
    "    grad3 = X[train_ind, 3]*(np.sum(w*X[train_ind, :])-y[train_ind])/len(y)\n",
    "    return  w - eta * np.array([grad0, grad1, grad2, grad3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        w_pred = stochastic_gradient_step(X, y, w, random_ind, eta=1e-2)\n",
    "        errors.append(mserror(y, linear_prediction(X, w)))\n",
    "        weight_dist = np.sum(np.abs(w - w_pred))\n",
    "        w = w_pred\n",
    "        iter_num += 1 \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X, y, w_init=[0,0,0,0], eta=1e-2, max_iter=1e5,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xa714fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8a8d710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xa6fee80>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQwCVXMYkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8a8d748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.92645619,   3.90900941,   2.72815222,   0.02019018])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7974276999826246"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.79745416647\n"
     ]
    }
   ],
   "source": [
    "answer4 = mserror(y, linear_prediction(X, stoch_grad_desc_weights))\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
